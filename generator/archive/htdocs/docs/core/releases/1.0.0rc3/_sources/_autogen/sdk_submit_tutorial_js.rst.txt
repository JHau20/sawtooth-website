.. /
   **********************************************************
   *                        WARNING!!!                      *
   * ------------------------------------------------------ *
   * This is an auto-generated file.  Do NOT modify!        *
   *                                                        *
   * Modifications should be made to the original template, *
   * or to the config file:                                 *
   *     - source/_templates/sdk_submit_tutorial.rst
   *     - source/_templates/template_config.yaml           *
   **********************************************************


************************************
Building and Submitting Transactions
************************************

The process of encoding information to be submitted to a distributed ledger is
generally non-trivial. A series of cryptographic safeguards are used to
confirm identity and data validity. *Hyperledger Sawtooth* is no different, but
the JavaScript SDK does provide client functionality that abstracts away
most of these details, and greatly simplifies the process of making changes to
the blockchain.


Creating a Private Key and Signer
=================================

In order to confirm your identity and sign the information you send to the
validator, you will need a 256-bit key. Sawtooth uses the secp256k1 ECSDA
standard for signing, which means that almost any set of 32 bytes is a valid
key. It is fairly simple to generate a valid key using the SDK's *signing*
module.

A *Signer* wraps a private key and provides some convenient methods for signing
bytes and getting the private key's associated public key.


.. code-block:: javascript

    const {createContext, CryptoFactory} = require('sawtooth-sdk/signing')

    const context = createContext('secp256k1')
    const privateKey = context.newRandomPrivateKey()
    const signer = CryptoFactory(context).newSigner(privateKey)


.. note::

   This key is the **only** way to prove your identity on the blockchain. Any
   person possessing it will be able to sign Transactions using your identity,
   and there is no way to recover it if lost. It is very important that any
   private key is kept secret and secure.


Encoding Your Payload
=====================

Transaction payloads are composed of binary-encoded data that is opaque to the
validator. The logic for encoding and decoding them rests entirely within the
particular Transaction Processor itself. As a result, there are many possible
formats, and you will have to look to the definition of the Transaction
Processor itself for that information. As an example, the *IntegerKey*
Transaction Processor uses a payload of three key/value pairs encoded as
`CBOR <https://en.wikipedia.org/wiki/CBOR>`_. Creating one might look like this:


.. code-block:: javascript

    const cbor = require('cbor')

    const payload = {
        Verb: 'set',
        Name: 'foo',
        Value: 42
    }

    const payloadBytes = cbor.encode(payload)


Building the Transaction
========================

*Transactions* are the basis for individual changes of state to the Sawtooth
blockchain. They are composed of a binary payload, a binary-encoded
*TransactionHeader* with some cryptographic safeguards and metadata about how
it should be handled, and a signature of that header. It would be worthwhile
to familiarize yourself with the information in
:doc:`/architecture/transactions_and_batches`, particularly the definition of
TransactionHeaders.


1. Create the Transaction Header
--------------------------------

A TransactionHeader contains information for routing a transaction to the
correct transaction processor, what input and output state addresses are
involved, references to prior transactions it depends on, and the public keys
associated with the its signature. The header references the payload through a
SHA-512 hash of the payload bytes.


.. code-block:: javascript

    const {createHash} = require('crypto')
    const {protobuf} = require('sawtooth-sdk')

    const transactionHeaderBytes = protobuf.TransactionHeader.encode({
        familyName: 'intkey',
        familyVersion: '1.0',
        inputs: ['1cf1266e282c41be5e4254d8820772c5518a2c5a8c0c7f7eda19594a7eb539453e1ed7'],
        outputs: ['1cf1266e282c41be5e4254d8820772c5518a2c5a8c0c7f7eda19594a7eb539453e1ed7'],
        signerPublicKey: signer.getPublicKey().asHex(),
        // In this example, we're signing the batch with the same private key,
        // but the batch can be signed by another party, in which case, the
        // public key will need to be associated with that key.
        batcherPublicKey: signer.getPublicKey().asHex(),
        // In this example, there are no dependencies.  This list should include
        // an previous transaction header signatures that must be applied for
        // this transaction to successfully commit.
        // For example,
        // dependencies: ['540a6803971d1880ec73a96cb97815a95d374cbad5d865925e5aa0432fcf1931539afe10310c122c5eaae15df61236079abbf4f258889359c4d175516934484a'],
        dependencies: [],
        payloadSha512: createHash('sha512').update(payloadBytes).digest('hex')
    }).finish()


.. note::

   Remember that a *batcher public_key* is the hex public key matching the private
   key that will later be used to sign a Transaction's Batch, and
   *dependencies* are the *header signatures* of Transactions that must be
   committed before this one (see *TransactionHeaders* in
   :doc:`/architecture/transactions_and_batches`).

.. note::

   The *inputs* and *outputs* are the state addresses a Transaction is allowed
   to read from or write to. With the Transaction above, we referenced the
   specific address where the value of  ``'foo'`` is stored.  Whenever possible,
   specific addresses should be used, as this will allow the validator to
   schedule transaction processing more efficiently.

   Note that the methods for assigning and validating addresses are entirely up
   to the Transaction Processor. In the case of IntegerKey, there are `specific
   rules to generate valid addresses <../transaction_family_specifications
   /integerkey_transaction_family.html#addressing>`_, which must be followed or
   Transactions will be rejected. You will need to follow the addressing rules
   for whichever Transaction Family you are working with.


2. Create the Transaction
-------------------------

Once the TransactionHeader is constructed, its bytes are then used to create a
signature.  This header signature also acts as the ID of the transaction.  The
header bytes, the header signature, and the payload bytes are all used to
construct the complete Transaction.


.. code-block:: javascript

    const signature = signer.sign(transactionHeaderBytes)

    const transaction = protobuf.Transaction.create({
        header: transactionHeaderBytes,
        headerSignature: signature,
        payload: payloadBytes
    })



3. (optional) Encode the Transaction(s)
---------------------------------------

If the same machine is creating Transactions and Batches there is no need to
encode the Transaction instances. However, in the use case where Transactions
are being batched externally, they must be serialized before being transmitted
to the batcher. The JavaScript SDK offers two options for this. One or more
Transactions can be combined into a serialized *TransactionList* method, or can
be serialized as a single Transaction.


.. code-block:: javascript

    const txnListBytes = protobuf.TransactionList.encode([
        transaction1,
        transaction2
    ]).finish()

    const txnBytes2 = transaction.finish()



Building the Batch
==================

Once you have one or more Transaction instances ready, they must be wrapped in a
*Batch*. Batches are the atomic unit of change in Sawtooth's state. When a Batch
is submitted to a validator each Transaction in it will be applied (in order),
or *no* Transactions will be applied. Even if your Transactions are not
dependent on any others, they cannot be submitted directly to the validator.
They must all be wrapped in a Batch.


1. Create the BatchHeader
-------------------------

Similar to the TransactionHeader, there is a *BatchHeader* for each Batch.
As Batches are much simpler than Transactions, a BatchHeader needs only  the
public key of the signer and the list of Transaction IDs, in the same order they
are listed in the Batch.



.. code-block:: javascript

    const transactions = [transaction]

    const batchHeaderBytes = protobuf.BatchHeader.encode({
        signerPublicKey: signer.getPublicKey().asHex(),
        transactionIds: transactions.map((txn) => txn.headerSignature),
    }).finish()



2. Create the Batch
-------------------

Using the SDK, creating a Batch is similar to creating a transaction.  The
header is signed, and the resulting signature acts as the Batch's ID.  The Batch
is then constructed out of the header bytes, the header signature, and the
transactions that make up the batch.


.. code-block:: javascript

    const signature = signer.sign(batchHeaderBytes)

    const batch = protobuf.Batch.create({
        header: batchHeaderBytes,
        headerSignature: signature,
        transactions: transactions
    }



3. Encode the Batch(es) in a BatchList
--------------------------------------

In order to submit Batches to the validator, they  must be collected into a
*BatchList*.  Multiple batches can be submitted in one BatchList, though the
Batches themselves don't necessarily need to depend on each other. Unlike
Batches, a BatchList is not atomic. Batches from other clients may be
interleaved with yours.


.. code-block:: javascript

    const batchListBytes = protobuf.BatchList.encode({
        batches: [batch]
    }).finish()


.. note::

   Note, if the transaction creator is using a different private key than the
   batcher, the *batcher public_key* must have been specified for every Transaction,
   and must have been generated from the private key being used to sign the
   Batch, or validation will fail.


Submitting Batches to the Validator
===================================

The prescribed way to submit Batches to the validator is via the REST API.
This is an independent process that runs alongside a validator, allowing clients
to communicate using HTTP/JSON standards. Simply send a *POST* request to the
*/batches* endpoint, with a *"Content-Type"* header of
*"application/octet-stream"*, and the *body* as a serialized *BatchList*.

There are a many ways to make an HTTP request, and hopefully the submission
process is fairly straightforward from here, but as an example, this is what it
might look if you sent the request from the same JavaScript process that
prepared the BatchList:


.. code-block:: javascript

    const request = require('request')

    request.post({
        url: 'http://rest.api.domain/batches',
        body: batchListBytes,
        headers: {'Content-Type': 'application/octet-stream'}
    }, (err, response) => {
        if (err) return console.log(err)
        console.log(response.body)
    })



And here is what it would look like if you saved the binary to a file, and then
sent it from the command line with ``curl``:


.. code-block:: javascript

    const fs = require('fs')

    const fileStream = fs.createWriteStream('intkey.batches')
    fileStream.write(batchListBytes)
    fileStream.end()


.. code-block:: bash

    % curl --request POST \
        --header "Content-Type: application/octet-stream" \
        --data-binary @intkey.batches \
        "http://rest.api.domain/batches"
